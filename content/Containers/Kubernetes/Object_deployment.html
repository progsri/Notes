<h2><strong> Deployment </strong></h2>
<hr>

<p>
    Is similar to object pod but better than object pod, it can handle group of pods. It can monitor the pods and update them 
  accordingly i.e maintain replicas / desired state as mentioned . We do not use object pod in production, we use deployment.
</p>

<p>
  To create a deployment client-deployment.yaml
  <pre class="language-yaml line-numbers"><code>
apiVersion: apps/v1
kind: Deployment
metadata:
  name: client-deployment
spec:
  replicas: 3
  selector:
  	matchLabels:
  	  component: web
  template:
    metadata:
      labels:
        component: web
    spec:
      containers:
      	-name: client
      	 image: stephengrider/multi-client
      	 ports:
      	   - containerPort: 3000
         livenessProbe:
           httpGet:
             path: /
             port: 8080
           initialDelaySeconds: 30
           periodSeconds: 30
         readinessProbe:
           httpGet:
             path: /
             port: 8080
           initialDelaySeconds: 15
           periodSeconds: 3
  
  </code></pre>
</p>
<p> 
    Creates 3(based on mentioned replicas) containers(pods) and assign a label web so that it can be linked to the
    networking layer via service object.
</p>
<p>
    <code> kubectl apply -f  client-deployment.yaml </code> then kubernetes will start maintaining the desired state as
    mentioned in the yaml configuration, this can be see via <code> kubectl gt deployments </code>
</p>
<p>
    Every pod created gets private ip address, to see ip <code> kubectl get pods -o wide </code> , if pod is terminated
    and recreated then it gets new ip address, this is exactly why we need service object so that when ever a request comes
    to the publicly exposed port via the nodePort on the service object, service would find all the matching pods with that
    match the selector key value pair of service to the label key value pair of pod and then forward the request to one of 
    the pod. <span class="text-danger"> It looks like in the background all pods when they are up they register to 
    a client discovery server that keeps the active pod, their ip address and their label information and servie simply would 
    look up this client discovery for the label it needs and gets their ip address to forward to that ip, but ip is private 
    to that node then  how does it work in a cluster ... is it possible that kubernetes makes sure that in a cluster no 2 
    nodes get the same private address and also has mapping of private adress to the node on which this pod is located.
    </span>
</p>
<p>
    we can increase the replicas by updating the config file then applying it or can be done via the dashboard as well.
</p>

<hr>
<h4><strong> Health check </strong></h4>
<p>
    <b> readinessProbe </b> tells kubernetes that the pod is ready to be live the first time it is created,
</p>
<p>
    <b> livenessProbe </b> tells kubernetes that the pod is still beating and can take traffic, kind of heartbeat
</p>
    
    
    


