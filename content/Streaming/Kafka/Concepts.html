<h2><strong> Kafka concepts </strong> </h2>
<hr>

<h4><strong> Topic </strong> </h4>
<p>
 Kafka needs <b> zookeeper </b>, Zookeeper does the below. Each broker is always connected to one zookeeper. To maintain a 
 kafka cluster, we need to maintain a zookeeper cluster as well. 
 <span class="text-danger"> what else does  zookeeper do </span>
 <ul>
  <li> Leader election for the partition copy. see below</li>
</ul>

<p>
 Each topic has to be divided into mulitple partitions, each partion is stored in different kafka broker. Which means to get
 all the data for a topic, we have to go to each broker and read the topic partition.
</p>
<p>
  What happens if a broker with a partion dies, we will loose the data. In order to prevent that each partition is replicated
  to othere brokers. To do this we use <mark> replication-factor </mark>. <mark> replication-factor </mark> of 1 indicates 
  there is only one copy of the data ( so ..it is not replicated ). <mark> replication-factor </mark> of 2 indicates 2 copies
  of data, one copy is the original and other is replicated copy also call <mark> ISR In Sync Replica</mark>. Now that a partiton 
  has 2 copies only one copy should be the active/master/leader and the other one whould be ISR, this is called <b> leader election
 </b> which is perforemd by <b>zookeeper</b>
</p>
<p>
 The order of messages in each partion is maintained. Each message is given a <mark> offset </mark>, Offset is just an ID in a
 partition. As all the data of a topic can be in different partition, order of message between 2 partition is <b>not</b>
 maintained.
</p>
<p>
 All the messages are persisted for a short time. <span class="text-danger"> which can be configured ?</span> 
<p>
<p>
 Once a message is written to a topic it is <b>immutable</b>, cannot be changed/updated.
</p>
<p>
 Each message sent to a topic would end up to a different partiton based on round robin algorithm, <span class="text-danger">
 however to always force to a particular partion key has to  be used. </span>
</p>
<p>
 Group of kafka broker form a cluster. Connecting to a a single broker gives access to entire cluster. which means each broker
 is a <b>master</b> just like rabbitmq but unlike redis when using sentinel. However partitions/data are <b>master/slave</b>,
 it is master/leader and slaves where master is the orginal copy and slaves are ISR.
 <span class="text-danger"> How is the cluster formed... how does one broker know about another broker</span>
</p>

<hr>
<h4><strong> Producer </strong> </h4>
<p>
   Producer sends messages to a topic to any broker.They do not choose a particular broker or partition. <mark> Broker discovery
 </mark> is the way any broker would know any other broker info and the metadata such as topics and which broker they are present,
 topics etc. So, the broker which the producer is connected would now the reqquired information by broker discovery.
</p>
<p>
 When producer writes to a topic, it can set acknowledgement for the write.
 <ul>
  <li>ack = 0 indicates the producer does not wait for ack, this is fastest but does not guarantee if the message is success</li> 
  <li>ack = 1 indicates the producer  will only wait for the ack from leader, does not gaurantee if the message is replicated,
    so, the broker of the leader copy dies before the message is the replicated, then there is a chance of losing that data.
  </li> 
  <li>ack = all or -1 indicatea the producer will wait for the ack from leader and replicas, this would of course be slow.</li> 
 </ul>
</p>
<p>
 <span class="text-danger">Producer can write to the same partition by using a key </span>, otherwise writes go to different partitions using round
 robin algorithm
</p>
<p>
 using <b> transactions </b> we can either rollback or commit the transaction, this is useful when writing to multiple topics.
</p>

<hr>
<h4><strong> Consumer </strong> </h4>
<p>
   Consumer gets messages from a topic from any broker it is connected to.They do not choose a particular broker or partition. <mark> Broker discovery
 </mark> is the way any broker would know any other broker info and the metadata such as topics and which broker they are present,
 topics etc. So, the broker which the consumer is connected would now the required information by broker discovery.
</p>
<p>
 For a particular partition, order of messages is gauranteed.
</p>
<p>
 Lets say we hava topic that has 3 partitions, how would one consumber read from 3 partitions at the same time or
 <span class="text-danger">Can it ? </span>. For this we use consumer groups which contains of group of consumers, each consumer
 can read from one or mode partitions, but never will a partition be read by 2 or more consumers in a consumber group, this 
 way the partitions can be consumer in parallel ( balancing the load ).
</p>
<p>
   Consumer can process a single message or group of messages(batch) at a time. This <u> <a href="https://kafka.apache.org/23/javadoc/index.html?org/apache/kafka/clients/consumer/KafkaConsumer.html">
 Diferent approaches </a> </u>
</p>
<p> This is a pull based i.e the broker does not give us the message until the consumer asks for one. consumer is supposed to
 keep polling. <span class="text-danger"> Polling is inefficient...then why is kafka entertainging this</span>
</p>
 
<hr>
<h4><strong> Consumer Groups</strong> </h4>
<p>
  Helps to load balance the reads. Consumer can have consumber that are not active( they are not reading )
</p>
<p>
  Consists of consumers that read data of topic from multiple partitions parallely. a consumer can read from multiple 
 partitions but a partition cannot be read by multiple consumers in a consumer group. A partition can  be read by multiple
 consumer if each consumer belongs to different consumber group.
</p>

<hr>
<h4><strong> Consumer offset </strong> </h4>
<p>
 Consumer offset tells the broker or cluster which offset in a partition a consumer has read. These are recorded in a topic
 called <b> _consumer_offset </b>
</p>
<p>
 consumer tells the broker the read offset by 3 modes:
<ul>
 <li> at most once ... when it receives the message but if it dies while processing, this would be not considered for reprocessing</li>
  <li> at least once ... when it received and processed .... this is the safest.</li>
 <li> <span class="text-danger">Exactly once </span> </li>
</ul>
</p>
<p>
 Consumer offset is just a way to telling the broker that a consumer is done reading that message from a particular partion.
 so that when this consumer needs another message or a new consumer is starting to read from the same partion, kafka would
 know where to start from. Whether it is a single consumer in default group assigned by kafka or group of consumer in a 
 consumer group, offsets can be reset for a particular topic in the group or all topics in the group.
</p>
<p>
  To display error message if a sub component fails, use <ErrorBoundary> and ComponentDidCatch lifecycle, this will display
 a default error html page instead of react's error page.
</p>
 <p>
  assign and seek go in combination. assign is about the partitions it should read from and seek is the offset in the 
  partition. When the consumer polls it would pool from this partition and offset.
</p>
