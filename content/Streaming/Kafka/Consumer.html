<h2><strong> Consumer </strong></h2>
<hr>

<h4><strong> Observations </strong></h4>
<p>
  consumers are listeners, in other messaging system a consumer or listenser is subscribed to the broker on a topic, 
    if a msg is written to that topic, the broker would send to the listener if it is avaialable, in case the listener is not
    available then the message is lost unless we have storage mechanism <span class="text-danger"> even in this case how do 
    they get back the lost messages </span>. In case of kafka, the broker doest not send, it is the cuty of the consumer to
    pool the messages.
</p>

<h4><strong> Connection Pooling </strong></h4>
<p> The library provided by kafka itself takes care of connection pool just like <b> jedis library  </b> takes care for redis.
</p>

<hr>
<h4><strong> Simple </strong></h4>
<p class="text-danger"> Is not polling inefficient ? </p>
<p>
    In the below code we are not subscribing to the broker, in kafka broker does not entertain such things like other
messaging systems, we are subscribing to the consumer library code ( imagine like Rxjava )
</p>
<p>
  we can also subscribe to multiple topics. 
 </p>
<p>
  Observe that the library gives messages in batch ( group of messages )
</p>
<pre class="language-java line-numbers"><code>
package com.ninjashore.kafka.producer;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;

import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

public class Consumer {

    public static void main(String[] args){

        String bootStrapServers = "127.0.0.1:9092";
        Properties properties = new Properties();
        properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,bootStrapServers);
        properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
        properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG,"group-1");
        properties.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,"earliest");

        KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(properties);

        consumer.subscribe(Arrays.asList("topic-6"));

        while(true){
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100)); // polling is inefficient ??

            for (ConsumerRecord<String,String> consumerRecord : records){
                System.out.println("key " + consumerRecord.key());
                System.out.println("Value " + consumerRecord.value());
                System.out.println("Partition " + consumerRecord.partition());
                System.out.println("Offset " + consumerRecord.offset());
                System.out.println(" --------------- ");
            }
        }


    }
}

</code></pre>

<hr>
<h4><strong> Rebalancing </strong></h4>
<p>
  When ever a consumer joins or leaves a consumer group, kafka automatically rebalancing the load. 
  For example take a topic with 3 partitons. When the first consumer joins kafka assigns all the 3 partitions to this 
  consumer, when the second consumer joins this group  then kafka rebalances the partitions, it takes away one or more
  partitions from the consumer one and assigns to second consumer. Similarly when a consumer leaves the partitions it was
  assigned would be assigned to other existing consumers in that group.
</p>
<p>
  when rebalancing happens the existing or new consumer would be slow.
</p>

<hr>
<h4><strong> assign and seek  </strong></h4>
<p>
    <b> Reading from a partition </b> assign and seek go in combination. assign is about the partitions it should read from and seek is the offset in the 
  partition. When the consumer polls it would pool from this partition and offset.
</p>


<hr>
<h4><strong> Idempotence  </strong></h4>
<p>
  Sometimes when the consumer processes group of messages and just before acknowleging kafka dies, then the next consumber 
  will reporcess all the messages again. This would cause duplicates on the end system consumer is writing to. So it is always 
  better to use an ID which would help the end systems to know it is a duplicate. One such ID would be combination of topic,
  partition, offset. In case of mongo we can use upsert where if record does not exist it will insert otherwise it would
  update... perfect for idempotence. but <span class="text-danger"> how do we do this for RDBMS ( postgres ) </span>
</p>

<hr>
<h4><strong> Commit strategy  </strong></h4>
<p>
  by default Producer is in auto commit mode.
</p>




